{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Künstliche Intelligenz: Einführung\n",
    "\n",
    "Die Künstliche Intelligenz ist ein weites Feld, das man aus verschiedenen Perspektiven betrachten kann.\n",
    "\n",
    "Fürs Abitur am TG Informationstechnik sind im Augenblick nur die folgenden Themen relevant - und in diesem Skript werden deshalb auch nur sie ausführlich behandelt. In unserem *Moodle-Kurs* findest du weitere Materialien, insb. zu den gesellschaflichen Auswirkungen von KI und dazu, wie du selbst KI nutzen kannst, sollst, darfst (und an manchen Stellen auch besser *nicht* nutzen sollst oder darfst) .\n",
    "\n",
    "## KI-Themen, die fürs Abitur in Informationstechnik relevant sind\n",
    "\n",
    "* Der k-Nächste-Nachbarn-Algorithmus\n",
    "* k-Means-Clustering\n",
    "* Entscheidungsbaumlernen\n",
    "* Der Minimax-Algorithmus für Zwei-Personen-Spiele\n",
    "* Neuronale Netze\n",
    "\n",
    "## Wichtige Begriffe\n",
    "\n",
    "Die KI ist voller Fachbegriffe. Hier kannst du nachschlagen, wenn du auf einen Begriff stößt, den du nicht kennst.\n",
    "\n",
    "(aktivierungsfunktion)=\n",
    "Aktivierungsfunktion  \n",
    ": Eine mathematische Funktion, die die Ausgabe eines künstlichen [Neurons](#neuron) transformiert. Sie entscheidet, ob ein Neuron \"aktiviert\" wird. Beispiele: Sigmoid, ReLU, Heaviside. (s. [Neuronales Netz](#neuronales-netz), [Perzeptron](#perzeptron))\n",
    "\n",
    "(backpropagation)=\n",
    "Backpropagation  \n",
    ": Eine Methode, die es einem [Neuronalen Netz](#neuronales-netz) ermöglicht, Fehler zu korrigieren, indem es sie rückwärts durch die Schichten sendet. Das Modell passt so seine Gewichte an, um bessere Vorhersagen zu treffen. (s. [Gradientenabstieg](#gradientenabstieg), [Trainingsdaten](#trainingsdaten))\n",
    "\n",
    "(bestaerkendes-lernen)=\n",
    "Bestärkendes Lernen  \n",
    ": (s. [Verstärkendes Lernen](#verstaerkendes-lernen))\n",
    "\n",
    "(datenpunkt)=\n",
    "Datenpunkt  \n",
    ": Eine einzelne Beobachtung in einem Datensatz, bestehend aus [Features](#feature) und ggf. einem [Label](#label). Beispiel: Ein Datenpunkt könnte das Alter und Gewicht einer Person enthalten.\n",
    "\n",
    "(distanzmasse)=\n",
    "Distanzmaße  \n",
    ": Metriken zur Messung der Ähnlichkeit oder Unterschiedlichkeit zwischen [Datenpunkten](#datenpunkt). Beispiele: Euklidische Distanz, [Manhattan-Distanz](#manhattan-distanz).\n",
    "\n",
    "(eifriger-lerner)=\n",
    "Eifriger Lerner  \n",
    ": Ein Ansatz, bei dem das Modell vollständig trainiert wird, bevor es Vorhersagen trifft. Beispiele: [Entscheidungsbaumlernen](#entscheidungsbaumlernen), [Neuronales Netz](#neuronales-netz). (s. [Fauler Lerner](#fauler-lerner))\n",
    "\n",
    "(fauler-lerner)=\n",
    "Fauler Lerner  \n",
    ": Ein Ansatz, bei dem das Modell erst zur Laufzeit (also bei einer Anfrage) trainiert wird, anstatt vorher. Beispiele: [K-Nächste-Nachbarn-Algorithmus](#k-naechste-nachbarn-algorithmus). (s. [Eifriger Lerner](#eifriger-lerner))\n",
    "\n",
    "(klassifikation)=\n",
    "Klassifikation  \n",
    ": Eine Form des [überwachten Lernens](#ueberwachtes-lernen), bei der ein Modell Eingabedaten einer oder mehreren Kategorien zuordnet. Beispiel: Ein Modell klassifiziert E-Mails als \"Spam\" oder \"Nicht-Spam\". (s. [Regression](#regression))\n",
    "\n",
    "(entscheidungsbaum)=\n",
    "Entscheidungsbaum  \n",
    ": Eine hierarchische Struktur, die Entscheidungen durch Regeln modelliert, z. B. \"Ist das Alter > 18?\". Jeder Knoten repräsentiert eine Regel, die die Daten aufteilt. (s. [Entscheidungsbaumlernen](#entscheidungsbaumlernen), [Gini-Unreinheit](#gini-unreinheit))\n",
    "\n",
    "(entscheidungsbaumlernen)=\n",
    "Entscheidungsbaumlernen  \n",
    ": Ein Algorithmus, der einen [Entscheidungsbaum](#entscheidungsbaum) erstellt, indem er die Daten basierend auf Kriterien wie der [Gini-Unreinheit](#gini-unreinheit) aufteilt.\n",
    "\n",
    "(epoche)=\n",
    "Epoche  \n",
    ": Eine vollständige Iteration durch den gesamten [Trainingsdatensatz](#trainingsdaten) während des Trainings eines Modells.\n",
    "\n",
    "(feature)=\n",
    "Feature  \n",
    ": (s. [Merkmal](#merkmal))\n",
    "\n",
    "(gini-unreinheit)=\n",
    "Gini-Unreinheit  \n",
    ": Ein Maß für die Reinheit eines Knotens in einem [Entscheidungsbaum](#entscheidungsbaum). Ein Wert von 0 bedeutet, dass alle Daten zur gleichen Kategorie gehören.\n",
    "\n",
    "(gradientenabstieg)=\n",
    "Gradientenabstieg  \n",
    ": Ein Algorithmus, der Schritt für Schritt die Fehler eines Modells reduziert, indem er die Parameter so anpasst, dass die Fehlerfunktion kleiner wird. (s. [Backpropagation](#backpropagation), [Lernrate](#lernrate))\n",
    "\n",
    "(k-means)=\n",
    "k-Means Clustering  \n",
    ": Ein Algorithmus, der [Datenpunkte](#datenpunkt) in \\(k\\) Gruppen (Cluster) aufteilt, indem er iterativ ihre Ähnlichkeit optimiert.\n",
    "\n",
    "(k-naechste-nachbarn-algorithmus)=\n",
    "k-Nächste-Nachbarn-Algorithmus  \n",
    ": Ein Algorithmus, der Vorhersagen basierend auf den \\(k\\) ähnlichsten [Datenpunkten](#datenpunkt) trifft. Beispiel: Die 3 nächsten Nachbarn eines Punktes bestimmen, ob er eher \"Katze\" oder \"Hund\" ist. (s. [Distanzmaße](#distanzmasse))\n",
    "\n",
    "(label)=\n",
    "Label  \n",
    ": Die bekannte Zielgröße oder Kategorie eines [Datenpunkts](#datenpunkt), z. B. \"Spam\" oder \"Nicht-Spam\". (s. [Gelabelte vs ungelabelte Daten](#gelabelte-daten))\n",
    "\n",
    "(lerner-vs-loeser)=\n",
    "Lerner vs Löser  \n",
    ": **Lerner** sind Algorithmen, die ein Modell aus Daten erstellen, z. B. [Neuronale Netze](#neuronales-netz) oder [Entscheidungsbaumlernen](#entscheidungsbaumlernen). **Löser** arbeiten direkt auf einer Problemstruktur, z. B. der [Minimax-Algorithmus](#minimax-algorithmus).\n",
    "\n",
    "(lernrate)=\n",
    "Lernrate  \n",
    ": Ein Hyperparameter, der bestimmt, wie groß die Schritte beim [Gradientenabstieg](#gradientenabstieg) sind. Eine zu hohe Lernrate kann das Lernen instabil machen, eine zu niedrige führt zu langsamen Fortschritten.\n",
    "\n",
    "(manhattan-distanz)=\n",
    "Manhattan-Distanz  \n",
    ": Eine Distanzmetrik, die die Summe der absoluten Differenzen zwischen den Koordinaten zweier Punkte berechnet. (s. [Distanzmaße](#distanzmasse)). Beispiel: Die Manhattan-Distanz zwischen den Punkten (1, 2) und (4, 6) beträgt $|1-4| + |2-6| = 7$.\n",
    "\n",
    "(merkmal)=\n",
    "Merkmal\n",
    ": Merkmale (engl. *features*) beschreiben die Eigenschaften eines [Datenpunkts](#datenpunkt). Beispiel: In einem Datensatz über Personen könnten Merkmale wie *Alter* oder *Körpergröße* enthalten sein.\n",
    "\n",
    "(minimax-algorithmus)=\n",
    "Minimax-Algorithmus  \n",
    ": Ein Entscheidungsalgorithmus, der in Spielen wie Schach verwendet wird, um optimale Züge zu finden. Beispiel: Der Algorithmus berechnet den besten Zug, indem er den schlechtesten Zug des Gegners minimiert. (s. [Entscheidungsbaum](#entscheidungsbaum))\n",
    "\n",
    "(neuron)=\n",
    "Neuron, künstliches  \n",
    ": Die grundlegende Recheneinheit in einem [Neuronalen Netz](#neuronales-netz). Es nimmt Eingaben entgegen, verarbeitet sie mit einer [Aktivierungsfunktion](#aktivierungsfunktion) und gibt eine Ausgabe weiter. (s. [Perzeptron](#perzeptron))\n",
    "\n",
    "(neuronales-netz)=\n",
    "Neuronales Netz  \n",
    ": Ein Modell, das aus mehreren Schichten künstlicher [Neuronen](#neuron) besteht. Es lernt komplexe Muster, indem es die Verbindungen zwischen den Neuronen anpasst. (s. [Backpropagation](#backpropagation))\n",
    "\n",
    "(overfitting)=\n",
    "Overfitting  \n",
    ": Die Situation, wenn ein Modell die [Trainingsdaten](#trainingsdaten) zu genau lernt und dadurch schlecht auf neue Daten generalisiert. Beispiel: Ein Modell, das jeden Datenpunkt \"auswendig\" gelernt hat. (s. [Underfitting](#underfitting), [Regularisierung](#regularisierung))\n",
    "\n",
    "(perzeptron)=\n",
    "Perzeptron  \n",
    ": Das einfachste Modell eines künstlichen [Neurons](#neuron). Es trifft Entscheidungen basierend auf einer linearen Entscheidungsregel. Beispiel: Ein Perzeptron entscheidet, ob ein Punkt links oder rechts einer Linie liegt. (s. [Neuronales Netz](#neuronales-netz))\n",
    "\n",
    "(regression)=\n",
    "Regression  \n",
    ": Eine Form des [überwachten Lernens](#ueberwachtes-lernen), bei der ein Modell kontinuierliche Werte vorhersagt, z. B. den Preis eines Hauses. (s. [Klassifikation](#klassifikation))\n",
    "\n",
    "(softmax-funktion)=\n",
    "Softmax-Funktion  \n",
    ": Eine Methode, um die Ausgaben mehrerer Neuronen in Wahrscheinlichkeiten umzuwandeln, sodass ihre Summe genau 1 ergibt. Große Ausgabewerte werden stärker gewichtet, kleinere weniger. Beispiel: Ein Modell gibt aus, dass es zu 80 % \"Katze\" und zu 20 % \"Hund\" ist. (s. [Klassifikation](#klassifikation))\n",
    "\n",
    "(testdaten)=\n",
    "Testdaten  \n",
    ": Daten, die verwendet werden, um die Leistung eines Modells zu überprüfen. Beispiel: Neue Daten, die das Modell vorher nicht gesehen hat. (s. [Trainingsdaten](#trainingsdaten))\n",
    "\n",
    "(trainingsdaten)=\n",
    "Trainingsdaten  \n",
    ": Daten, die verwendet werden, um ein Modell zu trainieren. Beispiel: Ein Datensatz mit Bildern von Katzen und Hunden, den das Modell verwendet, um sie zu unterscheiden. (s. [Testdaten](#testdaten))\n",
    "\n",
    "(ueberwachtes-lernen)=\n",
    "Überwachtes Lernen  \n",
    ": Eine Lernmethode, bei der das Modell mit [gelabelten Daten](#gelabelte-daten) trainiert wird. Beispiel: Ein Modell lernt, Spam von Nicht-Spam zu unterscheiden.\n",
    "\n",
    "(unueberwachtes-lernen)=\n",
    "Unüberwachtes Lernen  \n",
    ": Eine Methode, bei der ein Modell mit ungelabelten Daten trainiert wird, um Muster oder Strukturen zu erkennen. Beispiel: Gruppieren von Kunden nach ihren Kaufgewohnheiten. (s. [Gelabelte vs ungelabelte Daten](#gelabelte-daten))\n",
    "\n",
    "(underfitting)=\n",
    "Underfitting  \n",
    ": Die Situation, wenn ein Modell zu einfach ist und die zugrunde liegenden Muster in den [Trainingsdaten](#trainingsdaten) nicht erfasst. Beispiel: Ein Modell, das eine komplexe Beziehung als gerade Linie darstellt. (s. [Overfitting](#overfitting))\n",
    "\n",
    "(verstaerkendes-lernen)=\n",
    "Verstärkendes Lernen  \n",
    ": Eine Methode, bei der ein Agent durch Belohnungen und Bestrafungen lernt, sein Verhalten zu optimieren. Beispiel: Ein Roboter lernt, einen Hindernisparcours zu meistern. (s. [Bestärkendes Lernen](#bestaerkendes-lernen))\n",
    "\n",
    "(zielmerkmal)=\n",
    "Zielmerkmal\n",
    ": Dasjenige Merkmal, das *vorhergesagt* werden soll. Beispiel: In einer Bilderdatenbank könnte das Zielmerkmal die Kategorie des Bildes sein, z. B. \"Katze\" oder \"Hund\". (s. [Merkmal](#merkmal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
